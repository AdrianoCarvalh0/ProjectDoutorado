{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dac9a5a",
   "metadata": {},
   "source": [
    "### NLM CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3f2c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import skimage.color\n",
    "import cupy as cp\n",
    "import time\n",
    "\n",
    "# Função para replicar bordas (mirror padding)\n",
    "def mirror(A, f):\n",
    "    n, m = A.shape\n",
    "    nlin = n + 2*f\n",
    "    ncol = m + 2*f\n",
    "    B = cp.zeros((nlin, ncol), dtype=A.dtype)\n",
    "    B[f:nlin-f, f:ncol-f] = A\n",
    "    B[0:f, 0:f] = cp.flip(A[0:f, 0:f])\n",
    "    B[0:f, ncol-f:ncol] = cp.flip(A[0:f, m-f:m])\n",
    "    B[nlin-f:nlin, 0:f] = cp.flip(A[n-f:n, 0:f])\n",
    "    B[nlin-f:nlin, ncol-f:ncol] = cp.flip(A[n-f:n, m-f:m])\n",
    "    B[0:f, f:ncol-f] = cp.flipud(A[0:f, :])\n",
    "    B[nlin-f:nlin, f:ncol-f] = cp.flipud(A[n-f:n, :])\n",
    "    B[f:nlin-f, 0:f] = cp.fliplr(A[:, 0:f])\n",
    "    B[f:nlin-f, ncol-f:ncol] = cp.fliplr(A[:, m-f:m])\n",
    "    return B\n",
    "\n",
    "nlm_kernel_shared_code = r'''\n",
    "extern \"C\" __global__\n",
    "void nlm_kernel_shared(\n",
    "    const float* img_n, float* output,\n",
    "    int m, int n, int f, int t, float h, int padded_width\n",
    ") {\n",
    "    int i = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int j = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    int Bx = blockDim.x;\n",
    "    int By = blockDim.y;\n",
    "\n",
    "    int pad = f + t;\n",
    "\n",
    "    int sh_width = Bx + 2 * pad;\n",
    "    int sh_height = By + 2 * pad;\n",
    "\n",
    "    extern __shared__ float sh_img[];\n",
    "\n",
    "    int base_i = blockIdx.y * blockDim.y + f - pad;\n",
    "    int base_j = blockIdx.x * blockDim.x + f - pad;\n",
    "\n",
    "    // Carrega patch expandido na shared memory\n",
    "    for (int y = threadIdx.y; y < sh_height; y += By) {\n",
    "        for (int x = threadIdx.x; x < sh_width; x += Bx) {\n",
    "            int img_i = base_i + y;\n",
    "            int img_j = base_j + x;\n",
    "\n",
    "            // Replicação de borda\n",
    "            int ii = img_i < 0 ? 0 : (img_i >= m + 2*f ? m + 2*f - 1 : img_i);\n",
    "            int jj = img_j < 0 ? 0 : (img_j >= n + 2*f ? n + 2*f - 1 : img_j);\n",
    "\n",
    "            sh_img[y * sh_width + x] = img_n[ii * padded_width + jj];\n",
    "        }\n",
    "    }\n",
    "    __syncthreads();\n",
    "\n",
    "    if (i >= m || j >= n) return;\n",
    "\n",
    "    int local_i = threadIdx.y + pad;\n",
    "    int local_j = threadIdx.x + pad;\n",
    "\n",
    "    float NL = 0.0f;\n",
    "    float Z = 0.0f;\n",
    "\n",
    "    int rmin = max(local_i - t, pad);\n",
    "    int rmax = min(local_i + t, By + pad - 1);\n",
    "    int smin = max(local_j - t, pad);\n",
    "    int smax = min(local_j + t, Bx + pad - 1);\n",
    "\n",
    "    for (int r = rmin; r <= rmax; ++r) {\n",
    "        for (int s = smin; s <= smax; ++s) {\n",
    "            float d2 = 0.0f;\n",
    "            for (int u = -f; u <= f; ++u) {\n",
    "                for (int v = -f; v <= f; ++v) {\n",
    "                    float diff = sh_img[(local_i + u) * sh_width + (local_j + v)] -\n",
    "                                 sh_img[(r + u) * sh_width + (s + v)];\n",
    "                    d2 += diff * diff;\n",
    "                }\n",
    "            }\n",
    "            float sij = __expf(-d2 / (h * h));\n",
    "            Z += sij;\n",
    "            NL += sij * sh_img[r * sh_width + s];\n",
    "        }\n",
    "    }\n",
    "    output[i * n + j] = NL / Z;\n",
    "}\n",
    "'''\n",
    "\n",
    "def NLM_fast_cuda_shared(img, h, f, t):\n",
    "    img = img.astype(cp.float32)\n",
    "    m, n = img.shape\n",
    "    padded = mirror(img, f)\n",
    "\n",
    "    kernel_code = nlm_kernel_shared_code.encode('ascii', 'ignore').decode('ascii')\n",
    "    module = cp.RawModule(code=kernel_code, options=('-std=c++11',))\n",
    "    #module = cp.RawModule(code=nlm_kernel_shared_code, options=('-std=c++11',))\n",
    "    kernel = module.get_function(\"nlm_kernel_shared\")\n",
    "\n",
    "    output = cp.zeros((m, n), dtype=cp.float32)\n",
    "\n",
    "    threads_per_block = (16, 16)\n",
    "    block_x = (n + threads_per_block[0] - 1) // threads_per_block[0]\n",
    "    block_y = (m + threads_per_block[1] - 1) // threads_per_block[1]\n",
    "    grid = (block_x, block_y)\n",
    "\n",
    "    sh_width = threads_per_block[0] + 2 * (f + t)\n",
    "    sh_height = threads_per_block[1] + 2 * (f + t)\n",
    "    shared_mem_size = sh_width * sh_height * 4  # float32 = 4 bytes\n",
    "\n",
    "    kernel(\n",
    "        grid, threads_per_block,\n",
    "        (\n",
    "            padded.ravel(), output.ravel(),\n",
    "            cp.int32(m), cp.int32(n), cp.int32(f), cp.int32(t),\n",
    "            cp.float32(h), cp.int32(padded.shape[1])\n",
    "        ),\n",
    "        shared_mem=shared_mem_size\n",
    "    )\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8af0942",
   "metadata": {},
   "source": [
    "### GEO NLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "289c145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "import skimage\n",
    "import statistics\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "import skimage.measure\n",
    "import numpy as np\n",
    "import sklearn.neighbors as sknn\n",
    "from scipy.sparse.csgraph import dijkstra\n",
    "from numpy.matlib import repmat\n",
    "from scipy.linalg import eigh\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import cond\n",
    "from numpy import eye\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from skimage.metrics import structural_similarity\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from numba import njit   # just in time compiler (acelera loops)\n",
    "from joblib import Parallel, delayed\n",
    "from bm3d import bm3d, BM3DProfile\n",
    "\n",
    "# Para evitar warning de divisão por zero\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "\n",
    "'''\n",
    "Non-Local Means geodésico (versão básica, sem paralelismo e mais lenta)\n",
    "\n",
    "Parâmetros:\n",
    "\n",
    "    img: imagem ruidosa de entrada\n",
    "    h: parâmetro que controla o grau de suavização (quanto maior, mais suaviza)\n",
    "    f: tamanho do patch (2f + 1 x 2f + 1) -> se f = 3, então patch é 7 x 7\n",
    "    t: tamanho da janela de busca (2t + 1 x 2t + 1) -> se t = 10, então janela de busca é 21 x 21\n",
    "    nn: número de vizinhos no grafo KNN\n",
    "\n",
    "''' \n",
    "def GeoNLM(img_noise, h, f, t, nn=10):\n",
    "    # Dimenssões espaciais da imagem\n",
    "    m, n = img_noise.shape\n",
    "    # Cria imagem de saída\n",
    "    filtrada = np.zeros((m, n))\n",
    "    # Problema de valor de contorno: replicar bordas\n",
    "    img_n = np.pad(img_noise, ((f, f), (f, f)), 'symmetric')\n",
    "    # Loop principal do NLM geodésico\n",
    "    for i in range(m):\n",
    "        if i % 10 == 0:\n",
    "            print(i, end=' ')\n",
    "            sys.stdout.flush()\n",
    "        for j in range(n):\n",
    "            im = i + f;   # compensar a borda adicionada artificialmente\n",
    "            jn = j + f;   # compensar a borda adicionada artificialmente\n",
    "            # Obtém o patch ao redor do pixel corrente\n",
    "            patch_central = img_n[im-f:(im+f)+1, jn-f:(jn+f)+1]\n",
    "            central = np.reshape(patch_central, [1, patch_central.shape[0]*patch_central.shape[1]])[-1]\n",
    "            # Calcula as bordas da janela de busca para o pixel corrente\n",
    "            rmin = max(im-t, f);  # linha inicial\n",
    "            rmax = min(im+t, m+f);  # linha final\n",
    "            smin = max(jn-t, f);  # coluna inicial\n",
    "            smax = min(jn+t, n+f);  # coluna final\n",
    "            # Calcula média ponderada\n",
    "            NL = 0      # valor do pixel corrente filtrado\n",
    "            Z = 0       # constante normalizadora\n",
    "            # Cria dataset com patches da janela de busca como vetores\n",
    "            num_elem = (rmax - rmin)*(smax - smin)\n",
    "            tamanho_patch = (2*f + 1)*(2*f + 1)\n",
    "            dataset = np.zeros((num_elem, tamanho_patch))\n",
    "            k = 0\n",
    "            pixels_busca = []\n",
    "            # Loop para montar o dataset com todos os patches da janela\n",
    "            for r in range(rmin, rmax):\n",
    "                for s in range(smin, smax):\n",
    "                    # Obtém o patch ao redor do pixel a ser comparado\n",
    "                    W = img_n[r-f:(r+f)+1, s-f:(s+f)+1] \n",
    "                    neighbor = np.reshape(W, [1, W.shape[0]*W.shape[1]])[-1]                    \n",
    "                    dataset[k, :] = neighbor.copy()\n",
    "                    if central[0] == neighbor[0]:\n",
    "                        if (central == neighbor).all():\n",
    "                            source = k\n",
    "                    pixels_busca.append(img_n[r, s])\n",
    "                    k = k + 1\n",
    "            # Cria grafo knn com patches da janela de busca\n",
    "            knnGraph = sknn.kneighbors_graph(dataset, n_neighbors=nn, mode='distance')\n",
    "            A = knnGraph.toarray()\n",
    "            # Converte matriz de adjacências para grafo\n",
    "            G = nx.from_numpy_array(A)                      \n",
    "            # Aplica algoritmo de Dijkstra\n",
    "            length, path = nx.single_source_dijkstra(G, source)\n",
    "            points = np.array(list(length.keys()))\n",
    "            distancias = np.array(list(length.values()))\n",
    "            # Calcula similaridades\n",
    "            similaridades = np.exp(-distancias**2/(h**2))\n",
    "            pixels = np.zeros(len(points))\n",
    "            pixels_busca = np.array(pixels_busca)\n",
    "            pixels = pixels_busca[points]\n",
    "            # Normalização do pixel filtrado\n",
    "            NL = sum(similaridades*pixels)\n",
    "            Z = sum(similaridades)\n",
    "            filtrada[i, j] = NL/Z\n",
    "    return filtrada\n",
    "\n",
    "\n",
    "######################################################\n",
    "# Função auxiliar para paralelizar o GEONLM\n",
    "######################################################\n",
    "def process_pixel(i, j, img_n, f, t, h, nn):\n",
    "    im = i + f\n",
    "    jn = j + f\n",
    "    patch_central = img_n[im-f:(im+f)+1, jn-f:(jn+f)+1]\n",
    "    central = np.reshape(patch_central, [1, patch_central.shape[0]*patch_central.shape[1]])[-1]\n",
    "    rmin = max(im-t, f)\n",
    "    rmax = min(im+t, m+f)\n",
    "    smin = max(jn-t, f)\n",
    "    smax = min(jn+t, n+f)\n",
    "    NL, Z = 0, 0\n",
    "    dataset = np.zeros(((rmax - rmin)*(smax - smin), (2*f + 1)*(2*f + 1)))\n",
    "    k = 0\n",
    "    pixels_busca = []\n",
    "    for r in range(rmin, rmax):\n",
    "        for s in range(smin, smax):\n",
    "            W = img_n[r-f:(r+f)+1, s-f:(s+f)+1]\n",
    "            neighbor = np.reshape(W, [1, W.shape[0]*W.shape[1]])[-1]\n",
    "            dataset[k, :] = neighbor.copy()\n",
    "            if central[0] == neighbor[0] and (central == neighbor).all():\n",
    "                source = k\n",
    "            pixels_busca.append(img_n[r, s])\n",
    "            k += 1\n",
    "    knnGraph = sknn.kneighbors_graph(dataset, n_neighbors=nn, mode='distance')\n",
    "    A = knnGraph.toarray()\n",
    "    G = nx.from_numpy_array(A)\n",
    "    length, path = nx.single_source_dijkstra(G, source)\n",
    "    points = np.array(list(length.keys()))\n",
    "    distancias = np.array(list(length.values()))\n",
    "    similaridades = np.exp(-distancias**2 / (h**2))\n",
    "    pixels_busca = np.array(pixels_busca)\n",
    "    pixels = pixels_busca[points]\n",
    "    NL = sum(similaridades * pixels)\n",
    "    Z = sum(similaridades)\n",
    "    return NL / Z\n",
    "\n",
    "##################################################\n",
    "# GEONLM paralelo \n",
    "##################################################\n",
    "def Parallel_GEONLM(img_n, f, t, h, nn):\n",
    "    # Parallelize the loop\n",
    "    print(f'img_n.shape: {img_n.shape}')\n",
    "    m = img_n.shape[0] - 2*f\n",
    "    print(f'M: {m}')\n",
    "    n = img_n.shape[1] - 2*f\n",
    "    print(f'N: {n}')\n",
    "    filtrada = Parallel(n_jobs=-1)(delayed(process_pixel)(i, j, img_n, f, t, h, nn) for i in range(m) for j in range(n))\n",
    "    #print(f\"filtrada Shape: {filtrada.shape}\")\n",
    "    \n",
    "    filtrada_geo = np.array(filtrada).reshape((m, n))\n",
    "    #print(f'filtrada_geo.shape: {filtrada_geo.shape}')\n",
    "    return filtrada_geo\n",
    "\n",
    "####################################################################\n",
    "'''\n",
    "Função que extrai os patches de cada janela de busca no GeoNLM\n",
    "Retorna uma matriz 4D (m, n, 2t+1 x 2t+1, 2f+1 x 2f+1)\n",
    "\n",
    "Usa o JIT (just in time) compiler para acelerar loops\n",
    "\n",
    "'''\n",
    "####################################################################\n",
    "@njit\n",
    "def Extract_patches(img, f, t):\n",
    "    # Dimenssões espaciais da imagem\n",
    "    m, n = img.shape\n",
    "    # Tamanhos do patch e da janela de busca\n",
    "    tamanho_patch = (2*f + 1)*(2*f + 1)    \n",
    "    # Patches para cada janela de busca\n",
    "    patches = []\n",
    "    centros = []    \n",
    "    # Problema de valor de contorno: replicar bordas\n",
    "    img_n = mirror(img, f)\n",
    "    # Loop principal do NLM geodésico\n",
    "    for i in range(m):        \n",
    "        for j in range(n):\n",
    "            im = i + f;   # compensar a borda adicionada artificialmente\n",
    "            jn = j + f;   # compensar a borda adicionada artificialmente\n",
    "            # Obtém o patch ao redor do pixel corrente\n",
    "            patch_central = img_n[im-f:(im+f)+1, jn-f:(jn+f)+1].copy()\n",
    "            central = patch_central.reshape((1, patch_central.shape[0]*patch_central.shape[1]))[-1]\n",
    "            # Calcula as bordas da janela de busca para o pixel corrente\n",
    "            rmin = max(im-t, f);  # linha inicial\n",
    "            rmax = min(im+t, m+f);  # linha final\n",
    "            smin = max(jn-t, f);  # coluna inicial\n",
    "            smax = min(jn+t, n+f);  # coluna final\n",
    "            num_elem = (rmax - rmin)*(smax - smin)\n",
    "            # Cria dataset\n",
    "            dataset = np.zeros((num_elem, tamanho_patch))\n",
    "            # Loop para montar o dataset com todos os patches da janela\n",
    "            k = 0\n",
    "            for r in range(rmin, rmax):\n",
    "                for s in range(smin, smax):\n",
    "                    # Obtém o patch ao redor do pixel a ser comparado\n",
    "                    W = img_n[r-f:(r+f)+1, s-f:(s+f)+1].copy() \n",
    "                    neighbor = W.reshape((1, W.shape[0]*W.shape[1]))[-1]\n",
    "                    dataset[k, :] = neighbor.copy()\n",
    "                    if (central == neighbor).all():\n",
    "                        source = k\n",
    "                    k = k + 1\n",
    "            patches.append(dataset)\n",
    "            centros.append(source)\n",
    "    return patches, centros\n",
    "\n",
    "###################################################################\n",
    "'''\n",
    "Função que extrai os patches de cada janela de busca no GeoNLM\n",
    "Retorna uma lista \n",
    "'''\n",
    "###################################################################\n",
    "def Geodesic_distances(patches, centros, nn=10):\n",
    "    distancias_geodesicas = []\n",
    "    pontos = []\n",
    "    # Percorre a lista de patches\n",
    "    for i in range(len(patches)):\n",
    "    # Cria grafo knn com patches da janela de busca\n",
    "        knnGraph = sknn.kneighbors_graph(patches[i], n_neighbors=nn, mode='distance')\n",
    "        A = knnGraph.toarray()        \n",
    "        G = nx.from_numpy_array(A)      # Converte matriz de adjacências para grafo\n",
    "        # Aplica algoritmo de Dijkstra\n",
    "        length, path = nx.single_source_dijkstra(G, centros[i])\n",
    "        points = np.array(list(length.keys()))\n",
    "        pontos.append(points)\n",
    "        geodists = np.array(list(length.values()))        \n",
    "        distancias_geodesicas.append(geodists)\n",
    "    return distancias_geodesicas, pontos\n",
    "\n",
    "##################################################################################################\n",
    "'''\n",
    "Non-Local Means geodésico (versão com compilador JIT para acelerar loops)\n",
    "\n",
    "Parâmetros:\n",
    "\n",
    "    img: imagem ruidosa de entrada\n",
    "    h: parâmetro que controla o grau de suavização (quanto maior, mais suaviza)\n",
    "    f: tamanho do patch (2f + 1 x 2f + 1) -> se f = 3, então patch é 7 x 7\n",
    "    t: tamanho da janela de busca (2t + 1 x 2t + 1) -> se t = 10, então janela de busca é 21 x 21\n",
    "    nn: número de vizinhos no grafo KNN\n",
    "\n",
    "''' \n",
    "###################################################################################################\n",
    "@njit\n",
    "def GeoNLM_fast(img, h, f, t, distancias_geodesicas, pontos):\n",
    "    # Dimenssões espaciais da imagem\n",
    "    m, n = img.shape\n",
    "    # Cria imagem de saída\n",
    "    filtrada = np.zeros((m, n))\n",
    "    # Problema de valor de contorno: replicar bordas\n",
    "    #img_n = np.pad(ruidosa, ((f, f), (f, f)), 'symmetric')\n",
    "    img_n = mirror(img, f)\n",
    "    # Loop principal do NLM geodésico\n",
    "    k = 0\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            im = i + f;   # compensar a borda adicionada artificialmente\n",
    "            jn = j + f;   # compensar a borda adicionada artificialmente    \n",
    "            # Calcula as bordas da janela de busca para o pixel corrente\n",
    "            rmin = max(im-t, f);  # linha inicial\n",
    "            rmax = min(im+t, m+f);  # linha final\n",
    "            smin = max(jn-t, f);  # coluna inicial\n",
    "            smax = min(jn+t, n+f);  # coluna final\n",
    "            # Calcula média ponderada\n",
    "            NL = 0      # valor do pixel corrente filtrado\n",
    "            Z = 0       # constante normalizadora            \n",
    "            pixels_busca = []\n",
    "            # Loop para montar o dataset com todos os patches da janela\n",
    "            for r in range(rmin, rmax):\n",
    "                for s in range(smin, smax):\n",
    "                    # Obtém o patch ao redor do pixel a ser comparado\n",
    "                    pixels_busca.append(img_n[r, s])\n",
    "            # Calcula similaridades\n",
    "            similaridades = np.exp(-distancias_geodesicas[k]**2/(h**2))\n",
    "            pixels = np.zeros(len(pontos[k]))\n",
    "            pixels_busca = np.array(pixels_busca)\n",
    "            pixels = pixels_busca[pontos[k]]\n",
    "            # Normalização do pixel filtrado\n",
    "            NL = sum(similaridades*pixels)\n",
    "            Z = sum(similaridades)\n",
    "            filtrada[i, j] = NL/Z\n",
    "            k = k + 1\n",
    "    return filtrada\n",
    "\n",
    "#########################################################################\n",
    "'''\n",
    "Realiza a filtragem da imagem com o filtro NLM geodésico \n",
    "\n",
    "Usa o compilador JIT para acelerar loops\n",
    "'''\n",
    "#########################################################################\n",
    "def GeoNLM_filter(img_noise, h, f, t, nn=10):\n",
    "    # Fase 1\n",
    "    print('Início da extração dos patches')\n",
    "    inicio = time.time()\n",
    "    patches, centros = Extract_patches(img_noise, f, t)\n",
    "    fim = time.time()\n",
    "    print('Elapsed time: %f ' %(fim - inicio))\n",
    "    print()\n",
    "    # Fase 2\n",
    "    print('Início do cálculo das distâncias')\n",
    "    inicio = time.time()\n",
    "    distancias_geodesicas, pontos = Geodesic_distances(patches, centros, nn)\n",
    "    fim = time.time()\n",
    "    print('Elapsed time: %f ' %(fim - inicio))\n",
    "    print()\n",
    "    # Fase 3\n",
    "    print('Início da filtragem')\n",
    "    inicio = time.time()\n",
    "    filtrada = GeoNLM_fast(img_noise, h, f, t, distancias_geodesicas, pontos)\n",
    "    fim = time.time()\n",
    "    print('Elapsed time: %f ' %(fim - inicio))\n",
    "    return filtrada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a99d244",
   "metadata": {},
   "source": [
    "### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bdc70ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "def read_directories(directory, img=None, exclude_json=None):\n",
    "    # Get a list of filenames in the specified directory\n",
    "    filenames = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if img is not None:\n",
    "            # If 'img' is provided, filter filenames containing it\n",
    "            if img in filename:   \n",
    "                filenames.append(filename)\n",
    "        elif exclude_json is not None:\n",
    "            filenames.append(filename.replace('.json',''))     \n",
    "        else:\n",
    "            filenames.append(filename)    \n",
    "    return filenames\n",
    "\n",
    "\n",
    "def add_poisson_noise(img):\n",
    "    \"\"\"\n",
    "    Aplica ruído de Poisson corretamente sem overflow, utilizando CuPy (GPU).\n",
    "\n",
    "    Parâmetros:\n",
    "        img (cp.ndarray): Imagem com valores em [0,255] ou [0,1].\n",
    "\n",
    "    Retorna:\n",
    "        cp.ndarray: imagem ruidosa, clipada para [0, 255], dtype uint8.\n",
    "    \"\"\"\n",
    "    # Se estiver em [0, 1], escala para 0-255\n",
    "    if cp.max(img) <= 1.0:\n",
    "        img = (img * 255).astype(cp.float32)\n",
    "    else:\n",
    "        img = img.astype(cp.float32)\n",
    "\n",
    "    # Garante que os valores Poisson não causem overflow\n",
    "    poisson_img = cp.random.poisson(img).astype(cp.float32)\n",
    "    poisson_img = cp.clip(poisson_img, 0, 255)\n",
    "\n",
    "    return poisson_img.astype(cp.uint8)\n",
    "\n",
    "\n",
    "def anscombe_transform(img):\n",
    "    return 2.0 * cp.sqrt(img.astype(cp.float32) + 3.0 / 8.0)\n",
    "\n",
    "def inverse_anscombe(transf_img):\n",
    "    return cp.clip((transf_img / 2.0) ** 2 - 3.0 / 8.0, 0, 255)\n",
    "\n",
    "def compute_adaptive_q(sigma_est):\n",
    "    q_nlm = 0.8 + 0.5 * cp.tanh(0.3 * (sigma_est - 1))\n",
    "    q_geo = 1.0 + 0.7 * cp.tanh(0.25 * (sigma_est - 1.5))\n",
    "\n",
    "    q_nlm = cp.clip(q_nlm, 0.7, 2.2) * 10\n",
    "    q_geo = cp.clip(q_geo, 0.9, 2.7) * 10\n",
    "\n",
    "    return q_nlm, q_geo\n",
    "\n",
    "import cupy as cp\n",
    "\n",
    "def add_poisson_gaussian_noise(image, gaussian_sigma=25):\n",
    "    \"\"\"\n",
    "    Adds Poisson noise followed by Gaussian noise to an image.\n",
    "\n",
    "    Parameters:\n",
    "        image (cp.ndarray): Input image (grayscale or RGB), values in [0, 1] or [0, 255].\n",
    "        gaussian_sigma (float): Standard deviation of the Gaussian noise (in intensity scale 0–255).\n",
    "\n",
    "    Returns:\n",
    "        cp.ndarray: Noisy image (clipped to [0, 255] and converted to uint8).\n",
    "    \"\"\"\n",
    "    # Convert to float32 and normalize to [0, 255] if necessary\n",
    "    if image.dtype != cp.float32:\n",
    "        image = image.astype(cp.float32)\n",
    "\n",
    "    if image.max() <= 1.0:\n",
    "        image *= 255.0\n",
    "\n",
    "    # Apply Poisson noise\n",
    "    poisson_image = cp.random.poisson(image).astype(cp.float32)\n",
    "\n",
    "    # Apply Gaussian noise\n",
    "    gaussian_noise = cp.random.normal(loc=0.0, scale=gaussian_sigma, size=image.shape)\n",
    "    noisy_image = poisson_image + gaussian_noise\n",
    "\n",
    "    # Clip values and convert to uint8\n",
    "    noisy_image = cp.clip(noisy_image, 0, 255).astype(cp.uint8)\n",
    "\n",
    "    return noisy_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e09de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "from skimage.restoration import estimate_sigma\n",
    "import cupy as cp\n",
    "\n",
    "\n",
    "def select_best_h_using_adaptive_q(img_original, img_ruidosa, f, t, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Seleciona o melhor h para NLM com base em pequenas variações de q_nlm,\n",
    "    utilizando a função compute_adaptive_q, com critério combinado PSNR e SSIM.\n",
    "\n",
    "    Parâmetros:\n",
    "    - img_original: imagem original sem ruído (uint8)\n",
    "    - img_ruidosa: imagem ruidosa (uint8)\n",
    "    - f, t: parâmetros do filtro NLM\n",
    "    - alpha: peso da PSNR (0 a 1). O restante (1-alpha) será o peso da SSIM\n",
    "\n",
    "    Retorna:\n",
    "    - h_nlm_final: melhor h para NLM\n",
    "    - h_geo_final: valor adaptado para GEONLM\n",
    "    \"\"\"\n",
    "\n",
    "    img_ruidosa_asc = anscombe_transform(img_ruidosa)\n",
    "    sigma_est = estimate_sigma(img_ruidosa_asc)\n",
    "    q_nlm_base, q_geo_base = compute_adaptive_q(sigma_est)\n",
    "\n",
    "    # Gera variações do q_nlm base com delta\n",
    "    q_nlm_candidates = cp.array([q_nlm_base + delta for delta in range(-20, 25, 5)])\n",
    "\n",
    "    melhor_score = -cp.inf\n",
    "    melhor_q_nlm = None\n",
    "\n",
    "    for q in q_nlm_candidates:\n",
    "        h_nlm = q * sigma_est\n",
    "        img_filt_asc = NLM_fast_cuda_shared(img_ruidosa_asc, h_nlm, f, t)\n",
    "        img_filt = inverse_anscombe(img_filt_asc).astype(cp.uint8)\n",
    "\n",
    "        # Calculando PSNR e SSIM\n",
    "        psnr = peak_signal_noise_ratio(cp.asnumpy(img_original), cp.asnumpy(img_filt))\n",
    "        ssim = structural_similarity(cp.asnumpy(img_original), cp.asnumpy(img_filt))\n",
    "\n",
    "        # Calculando o score combinado\n",
    "        score = alpha * psnr + (1 - alpha) * (ssim * 100)  # normaliza SSIM para escala próxima ao PSNR\n",
    "\n",
    "        print(f\"q = {q:.2f} | h = {h_nlm:.2f} | PSNR = {psnr:.2f} | SSIM = {ssim:.4f} | Score = {score:.2f}\")\n",
    "\n",
    "        if score > melhor_score:\n",
    "            melhor_score = score\n",
    "            melhor_q_nlm = q\n",
    "\n",
    "    h_nlm_final = melhor_q_nlm * sigma_est\n",
    "    h_geo_final = (melhor_q_nlm + 0.3) * sigma_est  # leve ajuste para mais suavização no GEONLM\n",
    "\n",
    "    print(f\"\\n[SELECIONADO] q_nlm = {melhor_q_nlm:.2f} | h_nlm = {h_nlm_final:.2f} | h_geo = {h_geo_final:.2f}\")\n",
    "\n",
    "    return h_nlm_final, h_geo_final, q_nlm_candidates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f556dae8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "O tamanho da imagem não é divisível pelo block_size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Redimensionar a imagem (downscale com CuPy)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m img \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39marray(img)\u001b[38;5;241m.\u001b[39mastype(cp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 55\u001b[0m img_downscaled \u001b[38;5;241m=\u001b[39m \u001b[43mdownscale_with_cp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Aplicar downscale com fator de escala 2\u001b[39;00m\n\u001b[1;32m     57\u001b[0m m, n \u001b[38;5;241m=\u001b[39m img_downscaled\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Adicionar ruído de Poisson\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 33\u001b[0m, in \u001b[0;36mdownscale_with_cp\u001b[0;34m(image, scale_factor)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Verificar se o tamanho é divisível pelo block_size\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;241m%\u001b[39m block_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n \u001b[38;5;241m%\u001b[39m block_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO tamanho da imagem não é divisível pelo block_size.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Divisão da imagem em blocos e calculando a média\u001b[39;00m\n\u001b[1;32m     36\u001b[0m image_reshaped \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mreshape(m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m block_size, block_size, n \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m block_size, block_size)\n",
      "\u001b[0;31mValueError\u001b[0m: O tamanho da imagem não é divisível pelo block_size."
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "from skimage.restoration import estimate_sigma\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "from pathlib import Path\n",
    "\n",
    "# Função para downscale com CuPy\n",
    "def downscale_with_cp(image, scale_factor):\n",
    "    \"\"\"\n",
    "    Aplica downscale (média local) usando CuPy, redimensionando a imagem.\n",
    "    O downscale é feito aplicando a média sobre blocos.\n",
    "\n",
    "    Parâmetros:\n",
    "        image (cp.ndarray): imagem a ser reduzida (CuPy array).\n",
    "        scale_factor (float): fator de escala para downscale (deve ser um número positivo).\n",
    "\n",
    "    Retorna:\n",
    "        cp.ndarray: imagem com downscale (CuPy array).\n",
    "    \"\"\"\n",
    "    # Verifica se a imagem é 2D ou 3D\n",
    "    if len(image.shape) == 2:\n",
    "        m, n = image.shape\n",
    "    elif len(image.shape) == 3:\n",
    "        m, n, c = image.shape\n",
    "    else:\n",
    "        raise ValueError(\"A imagem deve ter 2 ou 3 dimensões (escala de cinza ou RGB).\")\n",
    "\n",
    "    block_size = int(scale_factor)\n",
    "\n",
    "    # Verificar se o tamanho é divisível pelo block_size\n",
    "    if m % block_size != 0 or n % block_size != 0:\n",
    "        raise ValueError(\"O tamanho da imagem não é divisível pelo block_size.\")\n",
    "\n",
    "    # Divisão da imagem em blocos e calculando a média\n",
    "    image_reshaped = image.reshape(m // block_size, block_size, n // block_size, block_size)\n",
    "    downscaled = image_reshaped.mean(axis=(1, 3))  # Calculando a média de cada bloco\n",
    "\n",
    "    return downscaled\n",
    "\n",
    "# Carregar a imagem\n",
    "img = skimage.io.imread('../images/0.gif')\n",
    "\n",
    "# Se for uma imagem com múltiplos quadros (por exemplo, GIF animado), pegamos o primeiro\n",
    "if img.ndim > 2 and img.shape[0] > 1:\n",
    "    img = img[0, :, :]\n",
    "\n",
    "# Se a imagem for colorida (RGB), converta para monocromática (escala de cinza)\n",
    "if len(img.shape) > 2:\n",
    "    img = skimage.color.rgb2gray(img)  # valores convertidos ficam entre 0 e 1\n",
    "    img = (255 * img).astype(cp.float32)  # Converte para [0,255]\n",
    "\n",
    "# Redimensionar a imagem (downscale com CuPy)\n",
    "img = cp.array(img).astype(cp.float32)\n",
    "img_downscaled = downscale_with_cp(img, 2)  # Aplicar downscale com fator de escala 2\n",
    "\n",
    "m, n = img_downscaled.shape\n",
    "\n",
    "# Adicionar ruído de Poisson\n",
    "noised_poisson = add_poisson_noise(img_downscaled)\n",
    "\n",
    "# Adicionar ruído Poisson + Gaussiano\n",
    "noised_poissongaussian = add_poisson_gaussian_noise(img_downscaled)\n",
    "\n",
    "# Garantir que as imagens de ruído fiquem entre 0 e 255\n",
    "noised_poisson[cp.where(noised_poisson > 255)] = 255\n",
    "noised_poisson[cp.where(noised_poisson < 0)] = 0\n",
    "\n",
    "noised_poissongaussian[cp.where(noised_poissongaussian > 255)] = 255\n",
    "noised_poissongaussian[cp.where(noised_poissongaussian < 0)] = 0\n",
    "\n",
    "# Selecionar o melhor h para NLM e GEONLM\n",
    "h_nlm, h_geo, q_nlm_candidates = select_best_h_using_adaptive_q(img_downscaled, noised_poisson, f=4, t=7, alpha=0.5)\n",
    "\n",
    "print(f'h_nlm: {h_nlm}, h_geo: {h_geo}, q_nlm_candidates: {q_nlm_candidates}')\n",
    "\n",
    "\n",
    "\n",
    "# f = 4\n",
    "# t = 7\n",
    "# # Cria imagem de saída\n",
    "# filtered = np.zeros((m, n))\n",
    "\n",
    "# # Problema de valor de contorno: replicar bordas\n",
    "# img_noised_poisson = np.pad(noised_poisson, ((f, f), (f, f)), 'symmetric')\n",
    "# img_noised_poisson_gaussian = np.pad(noised_poissongaussian, ((f, f), (f, f)), 'symmetric')\n",
    "\n",
    "# noised_anscombe_poisson = anscombe_transform(img_noised_poisson)\n",
    "# noised_anscombe_poisson_gaussian = anscombe_transform(img_noised_poisson_gaussian)\n",
    "\n",
    "\n",
    "# sigma_est_poisson = estimate_sigma(noised_anscombe_poisson)\n",
    "# sigma_est_poisson_gaussian = estimate_sigma(noised_anscombe_poisson_gaussian)\n",
    "\n",
    "# q_nlm, q_geo = compute_adaptive_q(sigma_est)\n",
    "# h_nlm = q_nlm * sigma_est #* 10\n",
    "# h_geo = q_geo * sigma_est #* 10\n",
    "\n",
    "\n",
    "# start = time.time()\n",
    "# result_img_noised_poisson = NLM_fast_cuda_shared(img_noised_poisson, h, f, t)\n",
    "# result_img_noised_poisson_gaussian = NLM_fast_cuda_shared(img_noised_poisson_gaussian, h, f, t)\n",
    "\n",
    "cp.cuda.Stream.null.synchronize()  # espera terminar GPU\n",
    "#print(\"Tempo GPU:\", time.time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b22703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
