{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dac9a5a",
   "metadata": {},
   "source": [
    "### NLM CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3f2c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import skimage.color\n",
    "import cupy as cp\n",
    "import time\n",
    "\n",
    "# Função para replicar bordas (mirror padding)\n",
    "def mirror(A, f):\n",
    "    n, m = A.shape\n",
    "    nlin = n + 2*f\n",
    "    ncol = m + 2*f\n",
    "    B = cp.zeros((nlin, ncol), dtype=A.dtype)\n",
    "    B[f:nlin-f, f:ncol-f] = A\n",
    "    B[0:f, 0:f] = cp.flip(A[0:f, 0:f])\n",
    "    B[0:f, ncol-f:ncol] = cp.flip(A[0:f, m-f:m])\n",
    "    B[nlin-f:nlin, 0:f] = cp.flip(A[n-f:n, 0:f])\n",
    "    B[nlin-f:nlin, ncol-f:ncol] = cp.flip(A[n-f:n, m-f:m])\n",
    "    B[0:f, f:ncol-f] = cp.flipud(A[0:f, :])\n",
    "    B[nlin-f:nlin, f:ncol-f] = cp.flipud(A[n-f:n, :])\n",
    "    B[f:nlin-f, 0:f] = cp.fliplr(A[:, 0:f])\n",
    "    B[f:nlin-f, ncol-f:ncol] = cp.fliplr(A[:, m-f:m])\n",
    "    return B\n",
    "\n",
    "nlm_kernel_shared_code = r'''\n",
    "extern \"C\" __global__\n",
    "void nlm_kernel_shared(\n",
    "    const float* img_n, float* output,\n",
    "    int m, int n, int f, int t, float h, int padded_width\n",
    ") {\n",
    "    int i = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int j = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    int Bx = blockDim.x;\n",
    "    int By = blockDim.y;\n",
    "\n",
    "    int pad = f + t;\n",
    "\n",
    "    int sh_width = Bx + 2 * pad;\n",
    "    int sh_height = By + 2 * pad;\n",
    "\n",
    "    extern __shared__ float sh_img[];\n",
    "\n",
    "    int base_i = blockIdx.y * blockDim.y + f - pad;\n",
    "    int base_j = blockIdx.x * blockDim.x + f - pad;\n",
    "\n",
    "    // Carrega patch expandido na shared memory\n",
    "    for (int y = threadIdx.y; y < sh_height; y += By) {\n",
    "        for (int x = threadIdx.x; x < sh_width; x += Bx) {\n",
    "            int img_i = base_i + y;\n",
    "            int img_j = base_j + x;\n",
    "\n",
    "            // Replicação de borda\n",
    "            int ii = img_i < 0 ? 0 : (img_i >= m + 2*f ? m + 2*f - 1 : img_i);\n",
    "            int jj = img_j < 0 ? 0 : (img_j >= n + 2*f ? n + 2*f - 1 : img_j);\n",
    "\n",
    "            sh_img[y * sh_width + x] = img_n[ii * padded_width + jj];\n",
    "        }\n",
    "    }\n",
    "    __syncthreads();\n",
    "\n",
    "    if (i >= m || j >= n) return;\n",
    "\n",
    "    int local_i = threadIdx.y + pad;\n",
    "    int local_j = threadIdx.x + pad;\n",
    "\n",
    "    float NL = 0.0f;\n",
    "    float Z = 0.0f;\n",
    "\n",
    "    int rmin = max(local_i - t, pad);\n",
    "    int rmax = min(local_i + t, By + pad - 1);\n",
    "    int smin = max(local_j - t, pad);\n",
    "    int smax = min(local_j + t, Bx + pad - 1);\n",
    "\n",
    "    for (int r = rmin; r <= rmax; ++r) {\n",
    "        for (int s = smin; s <= smax; ++s) {\n",
    "            float d2 = 0.0f;\n",
    "            for (int u = -f; u <= f; ++u) {\n",
    "                for (int v = -f; v <= f; ++v) {\n",
    "                    float diff = sh_img[(local_i + u) * sh_width + (local_j + v)] -\n",
    "                                 sh_img[(r + u) * sh_width + (s + v)];\n",
    "                    d2 += diff * diff;\n",
    "                }\n",
    "            }\n",
    "            float sij = __expf(-d2 / (h * h));\n",
    "            Z += sij;\n",
    "            NL += sij * sh_img[r * sh_width + s];\n",
    "        }\n",
    "    }\n",
    "    output[i * n + j] = NL / Z;\n",
    "}\n",
    "'''\n",
    "\n",
    "def NLM_fast_cuda_shared(img, h, f, t):\n",
    "    img = img.astype(cp.float32)\n",
    "    m, n = img.shape\n",
    "    padded = mirror(img, f)\n",
    "\n",
    "    kernel_code = nlm_kernel_shared_code.encode('ascii', 'ignore').decode('ascii')\n",
    "    module = cp.RawModule(code=kernel_code, options=('-std=c++11',))\n",
    "    #module = cp.RawModule(code=nlm_kernel_shared_code, options=('-std=c++11',))\n",
    "    kernel = module.get_function(\"nlm_kernel_shared\")\n",
    "\n",
    "    output = cp.zeros((m, n), dtype=cp.float32)\n",
    "\n",
    "    threads_per_block = (16, 16)\n",
    "    block_x = (n + threads_per_block[0] - 1) // threads_per_block[0]\n",
    "    block_y = (m + threads_per_block[1] - 1) // threads_per_block[1]\n",
    "    grid = (block_x, block_y)\n",
    "\n",
    "    sh_width = threads_per_block[0] + 2 * (f + t)\n",
    "    sh_height = threads_per_block[1] + 2 * (f + t)\n",
    "    shared_mem_size = sh_width * sh_height * 4  # float32 = 4 bytes\n",
    "\n",
    "    # kernel(\n",
    "    #     grid, threads_per_block,\n",
    "    #     (\n",
    "    #         padded.ravel(), output.ravel(),\n",
    "    #         cp.int32(m), cp.int32(n), cp.int32(f), cp.int32(t),\n",
    "    #         cp.float32(h), cp.int32(padded.shape[1])\n",
    "    #     ),\n",
    "    #     shared_mem=shared_mem_size\n",
    "    # )\n",
    "    # Parâmetros para o kernel\n",
    "    kernel_params = (\n",
    "        padded.ravel(), output.ravel(),\n",
    "        cp.int32(m), cp.int32(n), cp.int32(f), cp.int32(t),\n",
    "        cp.float32(h), cp.int32(padded.shape[1])\n",
    "    )\n",
    "\n",
    "    # Chamada ao kernel\n",
    "    kernel(\n",
    "        grid, threads_per_block,\n",
    "        kernel_params,\n",
    "        shared_mem=shared_mem_size\n",
    "    )\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8af0942",
   "metadata": {},
   "source": [
    "### GEO NLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "289c145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "import skimage\n",
    "import statistics\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "import skimage.measure\n",
    "import numpy as np\n",
    "import sklearn.neighbors as sknn\n",
    "from scipy.sparse.csgraph import dijkstra\n",
    "from numpy.matlib import repmat\n",
    "from scipy.linalg import eigh\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import cond\n",
    "from numpy import eye\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from skimage.metrics import structural_similarity\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from numba import njit   # just in time compiler (acelera loops)\n",
    "from joblib import Parallel, delayed\n",
    "from bm3d import bm3d, BM3DProfile\n",
    "\n",
    "# Para evitar warning de divisão por zero\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "\n",
    "'''\n",
    "Non-Local Means geodésico (versão básica, sem paralelismo e mais lenta)\n",
    "\n",
    "Parâmetros:\n",
    "\n",
    "    img: imagem ruidosa de entrada\n",
    "    h: parâmetro que controla o grau de suavização (quanto maior, mais suaviza)\n",
    "    f: tamanho do patch (2f + 1 x 2f + 1) -> se f = 3, então patch é 7 x 7\n",
    "    t: tamanho da janela de busca (2t + 1 x 2t + 1) -> se t = 10, então janela de busca é 21 x 21\n",
    "    nn: número de vizinhos no grafo KNN\n",
    "\n",
    "''' \n",
    "def GeoNLM(img_noise, h, f, t, nn=10):\n",
    "    # Dimenssões espaciais da imagem\n",
    "    m, n = img_noise.shape\n",
    "    # Cria imagem de saída\n",
    "    filtrada = np.zeros((m, n))\n",
    "    # Problema de valor de contorno: replicar bordas\n",
    "    img_n = np.pad(img_noise, ((f, f), (f, f)), 'symmetric')\n",
    "    # Loop principal do NLM geodésico\n",
    "    for i in range(m):\n",
    "        if i % 10 == 0:\n",
    "            print(i, end=' ')\n",
    "            sys.stdout.flush()\n",
    "        for j in range(n):\n",
    "            im = i + f;   # compensar a borda adicionada artificialmente\n",
    "            jn = j + f;   # compensar a borda adicionada artificialmente\n",
    "            # Obtém o patch ao redor do pixel corrente\n",
    "            patch_central = img_n[im-f:(im+f)+1, jn-f:(jn+f)+1]\n",
    "            central = np.reshape(patch_central, [1, patch_central.shape[0]*patch_central.shape[1]])[-1]\n",
    "            # Calcula as bordas da janela de busca para o pixel corrente\n",
    "            rmin = max(im-t, f);  # linha inicial\n",
    "            rmax = min(im+t, m+f);  # linha final\n",
    "            smin = max(jn-t, f);  # coluna inicial\n",
    "            smax = min(jn+t, n+f);  # coluna final\n",
    "            # Calcula média ponderada\n",
    "            NL = 0      # valor do pixel corrente filtrado\n",
    "            Z = 0       # constante normalizadora\n",
    "            # Cria dataset com patches da janela de busca como vetores\n",
    "            num_elem = (rmax - rmin)*(smax - smin)\n",
    "            tamanho_patch = (2*f + 1)*(2*f + 1)\n",
    "            dataset = np.zeros((num_elem, tamanho_patch))\n",
    "            k = 0\n",
    "            pixels_busca = []\n",
    "            # Loop para montar o dataset com todos os patches da janela\n",
    "            for r in range(rmin, rmax):\n",
    "                for s in range(smin, smax):\n",
    "                    # Obtém o patch ao redor do pixel a ser comparado\n",
    "                    W = img_n[r-f:(r+f)+1, s-f:(s+f)+1] \n",
    "                    neighbor = np.reshape(W, [1, W.shape[0]*W.shape[1]])[-1]                    \n",
    "                    dataset[k, :] = neighbor.copy()\n",
    "                    if central[0] == neighbor[0]:\n",
    "                        if (central == neighbor).all():\n",
    "                            source = k\n",
    "                    pixels_busca.append(img_n[r, s])\n",
    "                    k = k + 1\n",
    "            # Cria grafo knn com patches da janela de busca\n",
    "            knnGraph = sknn.kneighbors_graph(dataset, n_neighbors=nn, mode='distance')\n",
    "            A = knnGraph.toarray()\n",
    "            # Converte matriz de adjacências para grafo\n",
    "            G = nx.from_numpy_array(A)                      \n",
    "            # Aplica algoritmo de Dijkstra\n",
    "            length, path = nx.single_source_dijkstra(G, source)\n",
    "            points = np.array(list(length.keys()))\n",
    "            distancias = np.array(list(length.values()))\n",
    "            # Calcula similaridades\n",
    "            similaridades = np.exp(-distancias**2/(h**2))\n",
    "            pixels = np.zeros(len(points))\n",
    "            pixels_busca = np.array(pixels_busca)\n",
    "            pixels = pixels_busca[points]\n",
    "            # Normalização do pixel filtrado\n",
    "            NL = sum(similaridades*pixels)\n",
    "            Z = sum(similaridades)\n",
    "            filtrada[i, j] = NL/Z\n",
    "    return filtrada\n",
    "\n",
    "\n",
    "######################################################\n",
    "# Função auxiliar para paralelizar o GEONLM\n",
    "######################################################\n",
    "def process_pixel(i, j, img_n, f, t, h, nn):\n",
    "    im = i + f\n",
    "    jn = j + f\n",
    "    patch_central = img_n[im-f:(im+f)+1, jn-f:(jn+f)+1]\n",
    "    central = np.reshape(patch_central, [1, patch_central.shape[0]*patch_central.shape[1]])[-1]\n",
    "    rmin = max(im-t, f)\n",
    "    rmax = min(im+t, m+f)\n",
    "    smin = max(jn-t, f)\n",
    "    smax = min(jn+t, n+f)\n",
    "    NL, Z = 0, 0\n",
    "    dataset = np.zeros(((rmax - rmin)*(smax - smin), (2*f + 1)*(2*f + 1)))\n",
    "    k = 0\n",
    "    pixels_busca = []\n",
    "    for r in range(rmin, rmax):\n",
    "        for s in range(smin, smax):\n",
    "            W = img_n[r-f:(r+f)+1, s-f:(s+f)+1]\n",
    "            neighbor = np.reshape(W, [1, W.shape[0]*W.shape[1]])[-1]\n",
    "            dataset[k, :] = neighbor.copy()\n",
    "            if central[0] == neighbor[0] and (central == neighbor).all():\n",
    "                source = k\n",
    "            pixels_busca.append(img_n[r, s])\n",
    "            k += 1\n",
    "    knnGraph = sknn.kneighbors_graph(dataset, n_neighbors=nn, mode='distance')\n",
    "    A = knnGraph.toarray()\n",
    "    G = nx.from_numpy_array(A)\n",
    "    length, path = nx.single_source_dijkstra(G, source)\n",
    "    points = np.array(list(length.keys()))\n",
    "    distancias = np.array(list(length.values()))\n",
    "    similaridades = np.exp(-distancias**2 / (h**2))\n",
    "    pixels_busca = np.array(pixels_busca)\n",
    "    pixels = pixels_busca[points]\n",
    "    NL = sum(similaridades * pixels)\n",
    "    Z = sum(similaridades)\n",
    "    return NL / Z\n",
    "\n",
    "##################################################\n",
    "# GEONLM paralelo \n",
    "##################################################\n",
    "def Parallel_GEONLM(img_n, f, t, h, nn):\n",
    "    # Parallelize the loop\n",
    "    print(f'img_n.shape: {img_n.shape}')\n",
    "    m = img_n.shape[0] - 2*f\n",
    "    print(f'M: {m}')\n",
    "    n = img_n.shape[1] - 2*f\n",
    "    print(f'N: {n}')\n",
    "    filtrada = Parallel(n_jobs=-1)(delayed(process_pixel)(i, j, img_n, f, t, h, nn) for i in range(m) for j in range(n))\n",
    "    #print(f\"filtrada Shape: {filtrada.shape}\")\n",
    "    \n",
    "    filtrada_geo = np.array(filtrada).reshape((m, n))\n",
    "    #print(f'filtrada_geo.shape: {filtrada_geo.shape}')\n",
    "    return filtrada_geo\n",
    "\n",
    "####################################################################\n",
    "'''\n",
    "Função que extrai os patches de cada janela de busca no GeoNLM\n",
    "Retorna uma matriz 4D (m, n, 2t+1 x 2t+1, 2f+1 x 2f+1)\n",
    "\n",
    "Usa o JIT (just in time) compiler para acelerar loops\n",
    "\n",
    "'''\n",
    "####################################################################\n",
    "@njit\n",
    "def Extract_patches(img, f, t):\n",
    "    # Dimenssões espaciais da imagem\n",
    "    m, n = img.shape\n",
    "    # Tamanhos do patch e da janela de busca\n",
    "    tamanho_patch = (2*f + 1)*(2*f + 1)    \n",
    "    # Patches para cada janela de busca\n",
    "    patches = []\n",
    "    centros = []    \n",
    "    # Problema de valor de contorno: replicar bordas\n",
    "    img_n = mirror(img, f)\n",
    "    # Loop principal do NLM geodésico\n",
    "    for i in range(m):        \n",
    "        for j in range(n):\n",
    "            im = i + f;   # compensar a borda adicionada artificialmente\n",
    "            jn = j + f;   # compensar a borda adicionada artificialmente\n",
    "            # Obtém o patch ao redor do pixel corrente\n",
    "            patch_central = img_n[im-f:(im+f)+1, jn-f:(jn+f)+1].copy()\n",
    "            central = patch_central.reshape((1, patch_central.shape[0]*patch_central.shape[1]))[-1]\n",
    "            # Calcula as bordas da janela de busca para o pixel corrente\n",
    "            rmin = max(im-t, f);  # linha inicial\n",
    "            rmax = min(im+t, m+f);  # linha final\n",
    "            smin = max(jn-t, f);  # coluna inicial\n",
    "            smax = min(jn+t, n+f);  # coluna final\n",
    "            num_elem = (rmax - rmin)*(smax - smin)\n",
    "            # Cria dataset\n",
    "            dataset = np.zeros((num_elem, tamanho_patch))\n",
    "            # Loop para montar o dataset com todos os patches da janela\n",
    "            k = 0\n",
    "            for r in range(rmin, rmax):\n",
    "                for s in range(smin, smax):\n",
    "                    # Obtém o patch ao redor do pixel a ser comparado\n",
    "                    W = img_n[r-f:(r+f)+1, s-f:(s+f)+1].copy() \n",
    "                    neighbor = W.reshape((1, W.shape[0]*W.shape[1]))[-1]\n",
    "                    dataset[k, :] = neighbor.copy()\n",
    "                    if (central == neighbor).all():\n",
    "                        source = k\n",
    "                    k = k + 1\n",
    "            patches.append(dataset)\n",
    "            centros.append(source)\n",
    "    return patches, centros\n",
    "\n",
    "###################################################################\n",
    "'''\n",
    "Função que extrai os patches de cada janela de busca no GeoNLM\n",
    "Retorna uma lista \n",
    "'''\n",
    "###################################################################\n",
    "def Geodesic_distances(patches, centros, nn=10):\n",
    "    distancias_geodesicas = []\n",
    "    pontos = []\n",
    "    # Percorre a lista de patches\n",
    "    for i in range(len(patches)):\n",
    "    # Cria grafo knn com patches da janela de busca\n",
    "        knnGraph = sknn.kneighbors_graph(patches[i], n_neighbors=nn, mode='distance')\n",
    "        A = knnGraph.toarray()        \n",
    "        G = nx.from_numpy_array(A)      # Converte matriz de adjacências para grafo\n",
    "        # Aplica algoritmo de Dijkstra\n",
    "        length, path = nx.single_source_dijkstra(G, centros[i])\n",
    "        points = np.array(list(length.keys()))\n",
    "        pontos.append(points)\n",
    "        geodists = np.array(list(length.values()))        \n",
    "        distancias_geodesicas.append(geodists)\n",
    "    return distancias_geodesicas, pontos\n",
    "\n",
    "##################################################################################################\n",
    "'''\n",
    "Non-Local Means geodésico (versão com compilador JIT para acelerar loops)\n",
    "\n",
    "Parâmetros:\n",
    "\n",
    "    img: imagem ruidosa de entrada\n",
    "    h: parâmetro que controla o grau de suavização (quanto maior, mais suaviza)\n",
    "    f: tamanho do patch (2f + 1 x 2f + 1) -> se f = 3, então patch é 7 x 7\n",
    "    t: tamanho da janela de busca (2t + 1 x 2t + 1) -> se t = 10, então janela de busca é 21 x 21\n",
    "    nn: número de vizinhos no grafo KNN\n",
    "\n",
    "''' \n",
    "###################################################################################################\n",
    "@njit\n",
    "def GeoNLM_fast(img, h, f, t, distancias_geodesicas, pontos):\n",
    "    # Dimenssões espaciais da imagem\n",
    "    m, n = img.shape\n",
    "    # Cria imagem de saída\n",
    "    filtrada = np.zeros((m, n))\n",
    "    # Problema de valor de contorno: replicar bordas\n",
    "    #img_n = np.pad(ruidosa, ((f, f), (f, f)), 'symmetric')\n",
    "    img_n = mirror(img, f)\n",
    "    # Loop principal do NLM geodésico\n",
    "    k = 0\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            im = i + f;   # compensar a borda adicionada artificialmente\n",
    "            jn = j + f;   # compensar a borda adicionada artificialmente    \n",
    "            # Calcula as bordas da janela de busca para o pixel corrente\n",
    "            rmin = max(im-t, f);  # linha inicial\n",
    "            rmax = min(im+t, m+f);  # linha final\n",
    "            smin = max(jn-t, f);  # coluna inicial\n",
    "            smax = min(jn+t, n+f);  # coluna final\n",
    "            # Calcula média ponderada\n",
    "            NL = 0      # valor do pixel corrente filtrado\n",
    "            Z = 0       # constante normalizadora            \n",
    "            pixels_busca = []\n",
    "            # Loop para montar o dataset com todos os patches da janela\n",
    "            for r in range(rmin, rmax):\n",
    "                for s in range(smin, smax):\n",
    "                    # Obtém o patch ao redor do pixel a ser comparado\n",
    "                    pixels_busca.append(img_n[r, s])\n",
    "            # Calcula similaridades\n",
    "            similaridades = np.exp(-distancias_geodesicas[k]**2/(h**2))\n",
    "            pixels = np.zeros(len(pontos[k]))\n",
    "            pixels_busca = np.array(pixels_busca)\n",
    "            pixels = pixels_busca[pontos[k]]\n",
    "            # Normalização do pixel filtrado\n",
    "            NL = sum(similaridades*pixels)\n",
    "            Z = sum(similaridades)\n",
    "            filtrada[i, j] = NL/Z\n",
    "            k = k + 1\n",
    "    return filtrada\n",
    "\n",
    "#########################################################################\n",
    "'''\n",
    "Realiza a filtragem da imagem com o filtro NLM geodésico \n",
    "\n",
    "Usa o compilador JIT para acelerar loops\n",
    "'''\n",
    "#########################################################################\n",
    "def GeoNLM_filter(img_noise, h, f, t, nn=10):\n",
    "    # Fase 1\n",
    "    print('Início da extração dos patches')\n",
    "    inicio = time.time()\n",
    "    patches, centros = Extract_patches(img_noise, f, t)\n",
    "    fim = time.time()\n",
    "    print('Elapsed time: %f ' %(fim - inicio))\n",
    "    print()\n",
    "    # Fase 2\n",
    "    print('Início do cálculo das distâncias')\n",
    "    inicio = time.time()\n",
    "    distancias_geodesicas, pontos = Geodesic_distances(patches, centros, nn)\n",
    "    fim = time.time()\n",
    "    print('Elapsed time: %f ' %(fim - inicio))\n",
    "    print()\n",
    "    # Fase 3\n",
    "    print('Início da filtragem')\n",
    "    inicio = time.time()\n",
    "    filtrada = GeoNLM_fast(img_noise, h, f, t, distancias_geodesicas, pontos)\n",
    "    fim = time.time()\n",
    "    print('Elapsed time: %f ' %(fim - inicio))\n",
    "    return filtrada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a99d244",
   "metadata": {},
   "source": [
    "### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bdc70ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "def read_directories(directory, img=None, exclude_json=None):\n",
    "    # Get a list of filenames in the specified directory\n",
    "    filenames = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if img is not None:\n",
    "            # If 'img' is provided, filter filenames containing it\n",
    "            if img in filename:   \n",
    "                filenames.append(filename)\n",
    "        elif exclude_json is not None:\n",
    "            filenames.append(filename.replace('.json',''))     \n",
    "        else:\n",
    "            filenames.append(filename)    \n",
    "    return filenames\n",
    "\n",
    "\n",
    "def add_poisson_noise(img):\n",
    "    \"\"\"\n",
    "    Aplica ruído de Poisson corretamente sem overflow, utilizando CuPy (GPU).\n",
    "\n",
    "    Parâmetros:\n",
    "        img (cp.ndarray): Imagem com valores em [0,255] ou [0,1].\n",
    "\n",
    "    Retorna:\n",
    "        cp.ndarray: imagem ruidosa, clipada para [0, 255], dtype uint8.\n",
    "    \"\"\"\n",
    "    # Se estiver em [0, 1], escala para 0-255\n",
    "    if cp.max(img) <= 1.0:\n",
    "        img = (img * 255).astype(cp.float32)\n",
    "    else:\n",
    "        img = img.astype(cp.float32)\n",
    "\n",
    "    # Garante que os valores Poisson não causem overflow\n",
    "    poisson_img = cp.random.poisson(img).astype(cp.float32)\n",
    "    poisson_img = cp.clip(poisson_img, 0, 255)\n",
    "\n",
    "    return poisson_img.astype(cp.uint8)\n",
    "\n",
    "\n",
    "def anscombe_transform(img):\n",
    "    return 2.0 * cp.sqrt(img.astype(cp.float32) + 3.0 / 8.0)\n",
    "\n",
    "def inverse_anscombe(transf_img):\n",
    "    return cp.clip((transf_img / 2.0) ** 2 - 3.0 / 8.0, 0, 255)\n",
    "\n",
    "def compute_adaptive_q(sigma_est):\n",
    "    q_nlm = 0.8 + 0.5 * cp.tanh(0.3 * (sigma_est - 1))\n",
    "    q_geo = 1.0 + 0.7 * cp.tanh(0.25 * (sigma_est - 1.5))\n",
    "\n",
    "    q_nlm = cp.clip(q_nlm, 0.7, 2.2) * 10\n",
    "    q_geo = cp.clip(q_geo, 0.9, 2.7) * 10\n",
    "\n",
    "    return q_nlm, q_geo\n",
    "\n",
    "import cupy as cp\n",
    "\n",
    "def add_poisson_gaussian_noise(image, gaussian_sigma=25):\n",
    "    \"\"\"\n",
    "    Adds Poisson noise followed by Gaussian noise to an image.\n",
    "\n",
    "    Parameters:\n",
    "        image (cp.ndarray): Input image (grayscale or RGB), values in [0, 1] or [0, 255].\n",
    "        gaussian_sigma (float): Standard deviation of the Gaussian noise (in intensity scale 0–255).\n",
    "\n",
    "    Returns:\n",
    "        cp.ndarray: Noisy image (clipped to [0, 255] and converted to uint8).\n",
    "    \"\"\"\n",
    "    # Convert to float32 and normalize to [0, 255] if necessary\n",
    "    if image.dtype != cp.float32:\n",
    "        image = image.astype(cp.float32)\n",
    "\n",
    "    if image.max() <= 1.0:\n",
    "        image *= 255.0\n",
    "\n",
    "    # Apply Poisson noise\n",
    "    poisson_image = cp.random.poisson(image).astype(cp.float32)\n",
    "\n",
    "    # Apply Gaussian noise\n",
    "    gaussian_noise = cp.random.normal(loc=0.0, scale=gaussian_sigma, size=image.shape)\n",
    "    noisy_image = poisson_image + gaussian_noise\n",
    "\n",
    "    # Clip values and convert to uint8\n",
    "    noisy_image = cp.clip(noisy_image, 0, 255).astype(cp.uint8)\n",
    "\n",
    "    return noisy_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e09de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "from skimage.restoration import estimate_sigma\n",
    "import cupy as cp\n",
    "\n",
    "def select_best_h_using_adaptive_q(img_original, img_ruidosa, f, t, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Seleciona o melhor h para NLM com base em pequenas variações de q_nlm,\n",
    "    utilizando a função compute_adaptive_q, com critério combinado PSNR e SSIM.\n",
    "\n",
    "    Parâmetros:\n",
    "    - img_original: imagem original sem ruído (uint8)\n",
    "    - img_ruidosa: imagem ruidosa (uint8)\n",
    "    - f, t: parâmetros do filtro NLM\n",
    "    - alpha: peso da PSNR (0 a 1). O restante (1-alpha) será o peso da SSIM\n",
    "\n",
    "    Retorna:\n",
    "    - h_nlm_final: melhor h para NLM\n",
    "    - h_geo_final: valor adaptado para GEONLM\n",
    "    \"\"\"\n",
    "    \n",
    "    # Transformação de Anscombe na imagem ruidosa (usando CuPy)\n",
    "    img_ruidosa_asc = anscombe_transform(img_ruidosa)\n",
    "    \n",
    "    # Convertendo a imagem para NumPy antes de passar para estimate_sigma\n",
    "    sigma_est = estimate_sigma(cp.asnumpy(img_ruidosa_asc))  # Estimando o sigma\n",
    "    \n",
    "    # Obtendo os valores de q_nlm e q_geo\n",
    "    q_nlm_base, q_geo_base = compute_adaptive_q(sigma_est)\n",
    "\n",
    "    # Gera variações do q_nlm base com delta\n",
    "    q_nlm_candidates = cp.array([q_nlm_base + delta for delta in range(-20, 25, 5)])\n",
    "\n",
    "    melhor_score = -cp.inf\n",
    "    melhor_q_nlm = None\n",
    "\n",
    "    # Itera sobre os candidatos de q_nlm\n",
    "    for q in q_nlm_candidates:\n",
    "        h_nlm = q * sigma_est\n",
    "        img_filt_asc = NLM_fast_cuda_shared(img_ruidosa_asc, h_nlm, f, t)\n",
    "        img_filt = inverse_anscombe(img_filt_asc).astype(cp.uint8)\n",
    "\n",
    "        # Convertendo as imagens para NumPy antes de calcular PSNR e SSIM\n",
    "        psnr = peak_signal_noise_ratio(cp.asnumpy(img_original), cp.asnumpy(img_filt))\n",
    "        ssim = structural_similarity(cp.asnumpy(img_original), cp.asnumpy(img_filt))\n",
    "\n",
    "        # Calculando o score combinado\n",
    "        score = alpha * psnr + (1 - alpha) * (ssim * 100)  # normaliza SSIM para escala próxima ao PSNR\n",
    "\n",
    "        print(f\"q = {q:.2f} | h = {h_nlm:.2f} | PSNR = {psnr:.2f} | SSIM = {ssim:.4f} | Score = {score:.2f}\")\n",
    "\n",
    "        if score > melhor_score:\n",
    "            melhor_score = score\n",
    "            melhor_q_nlm = q\n",
    "\n",
    "    h_nlm_final = melhor_q_nlm * sigma_est\n",
    "    h_geo_final = (melhor_q_nlm + 0.3) * sigma_est  # leve ajuste para mais suavização no GEONLM\n",
    "\n",
    "    print(f\"\\n[SELECIONADO] q_nlm = {melhor_q_nlm:.2f} | h_nlm = {h_nlm_final:.2f} | h_geo = {h_geo_final:.2f}\")\n",
    "\n",
    "    return h_nlm_final, h_geo_final, q_nlm_candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f556dae8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 179\u001b[0m\n\u001b[1;32m    176\u001b[0m sigma_est \u001b[38;5;241m=\u001b[39m estimate_sigma(img_downscale_np)  \u001b[38;5;66;03m# Usando estimate_sigma no formato NumPy\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# Aqui você pode continuar com seu processo de seleção de h\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m h_nlm, h_geo, q_nlm_candidates \u001b[38;5;241m=\u001b[39m \u001b[43mselect_best_h_using_adaptive_q\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_downscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoised_poisson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# Exibir resultados\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh_nlm: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh_nlm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, h_geo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh_geo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, q_nlm_candidates: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq_nlm_candidates\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[23], line 32\u001b[0m, in \u001b[0;36mselect_best_h_using_adaptive_q\u001b[0;34m(img_original, img_ruidosa, f, t, alpha)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mSeleciona o melhor h para NLM com base em pequenas variações de q_nlm,\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03mutilizando a função compute_adaptive_q, com critério combinado PSNR e SSIM.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m- h_geo_final: valor adaptado para GEONLM\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m img_ruidosa_asc \u001b[38;5;241m=\u001b[39m anscombe_transform(img_ruidosa)\n\u001b[0;32m---> 32\u001b[0m sigma_est \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_sigma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_ruidosa_asc\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Você já está usando np, então isso está correto\u001b[39;00m\n\u001b[1;32m     33\u001b[0m q_nlm_base, q_geo_base \u001b[38;5;241m=\u001b[39m compute_adaptive_q(sigma_est)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Gera variações do q_nlm base com delta\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/skimage/restoration/_denoise.py:1126\u001b[0m, in \u001b[0;36mestimate_sigma\u001b[0;34m(image, average_sigmas, channel_axis)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1121\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage is size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on the last axis, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbut channel_axis is None. If this is a color image, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1123\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease set channel_axis=-1 for proper noise estimation.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1124\u001b[0m     )\n\u001b[1;32m   1125\u001b[0m     warn(msg)\n\u001b[0;32m-> 1126\u001b[0m coeffs \u001b[38;5;241m=\u001b[39m \u001b[43mpywt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdwtn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwavelet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdb2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m detail_coeffs \u001b[38;5;241m=\u001b[39m coeffs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m image\u001b[38;5;241m.\u001b[39mndim]\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _sigma_est_dwt(detail_coeffs, distribution\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGaussian\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pywt/_multidim.py:164\u001b[0m, in \u001b[0;36mdwtn\u001b[0;34m(data, wavelet, mode, axes)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdwtn\u001b[39m(data, wavelet, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymmetric\u001b[39m\u001b[38;5;124m'\u001b[39m, axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    Single-level n-dimensional Discrete Wavelet Transform.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _have_c99_complex \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39miscomplexobj(data):\n\u001b[1;32m    166\u001b[0m         real \u001b[38;5;241m=\u001b[39m dwtn(data\u001b[38;5;241m.\u001b[39mreal, wavelet, mode, axes)\n",
      "File \u001b[0;32mcupy/_core/core.pyx:1479\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base.__array__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly."
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "from skimage.restoration import estimate_sigma\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "from skimage.transform import downscale_local_mean\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "from skimage.restoration import estimate_sigma\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "\n",
    "\n",
    "def select_best_h_using_adaptive_q(img_original, img_ruidosa, f, t, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Seleciona o melhor h para NLM com base em pequenas variações de q_nlm,\n",
    "    utilizando a função compute_adaptive_q, com critério combinado PSNR e SSIM.\n",
    "\n",
    "    Parâmetros:\n",
    "    - img_original: imagem original sem ruído (uint8)\n",
    "    - img_ruidosa: imagem ruidosa (uint8)\n",
    "    - f, t: parâmetros do filtro NLM\n",
    "    - alpha: peso da PSNR (0 a 1). O restante (1-alpha) será o peso da SSIM\n",
    "\n",
    "    Retorna:\n",
    "    - h_nlm_final: melhor h para NLM\n",
    "    - h_geo_final: valor adaptado para GEONLM\n",
    "    \"\"\"\n",
    "\n",
    "    img_ruidosa_asc = anscombe_transform(img_ruidosa)\n",
    "    sigma_est = estimate_sigma(img_ruidosa_asc)  # Você já está usando np, então isso está correto\n",
    "    q_nlm_base, q_geo_base = compute_adaptive_q(sigma_est)\n",
    "\n",
    "    # Gera variações do q_nlm base com delta\n",
    "    q_nlm_candidates = cp.array([q_nlm_base + delta for delta in range(-20, 25, 5)])\n",
    "\n",
    "    melhor_score = -cp.inf\n",
    "    melhor_q_nlm = None\n",
    "\n",
    "    for q in q_nlm_candidates:\n",
    "        h_nlm = q * sigma_est\n",
    "        img_filt_asc = NLM_fast_cuda_shared(img_ruidosa_asc, h_nlm, f, t)\n",
    "        img_filt = inverse_anscombe(img_filt_asc).astype(cp.float32)\n",
    "\n",
    "        # Calcular PSNR e SSIM (usando .get() para converter de CuPy para NumPy)\n",
    "        psnr = peak_signal_noise_ratio(cp.asnumpy(img_original), cp.asnumpy(img_filt))\n",
    "        ssim = structural_similarity(cp.asnumpy(img_original), cp.asnumpy(img_filt))\n",
    "\n",
    "        # Calcular o score combinado\n",
    "        score = alpha * psnr + (1 - alpha) * (ssim * 100)  # normaliza SSIM para escala próxima ao PSNR\n",
    "\n",
    "        print(f\"q = {q:.2f} | h = {h_nlm:.2f} | PSNR = {psnr:.2f} | SSIM = {ssim:.4f} | Score = {score:.2f}\")\n",
    "\n",
    "        if score > melhor_score:\n",
    "            melhor_score = score\n",
    "            melhor_q_nlm = q\n",
    "\n",
    "    h_nlm_final = melhor_q_nlm * sigma_est\n",
    "    h_geo_final = (melhor_q_nlm + 0.3) * sigma_est  # Ajuste para maior suavização no GEONLM\n",
    "\n",
    "    print(f\"\\n[SELECIONADO] q_nlm = {melhor_q_nlm:.2f} | h_nlm = {h_nlm_final:.2f} | h_geo = {h_geo_final:.2f}\")\n",
    "\n",
    "    return h_nlm_final, h_geo_final, q_nlm_candidates\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Função para adicionar ruído de Poisson (com CuPy)\n",
    "def add_poisson_noise(img):\n",
    "    \"\"\"\n",
    "    Adiciona ruído de Poisson a uma imagem.\n",
    "    \n",
    "    Parâmetros:\n",
    "        img (cp.ndarray): imagem com valores entre [0, 255].\n",
    "\n",
    "    Retorna:\n",
    "        cp.ndarray: imagem com ruído de Poisson.\n",
    "    \"\"\"\n",
    "    # Aplica ruído Poisson\n",
    "    poisson_img = cp.random.poisson(img).astype(cp.float32)\n",
    "    poisson_img = cp.clip(poisson_img, 0, 255)\n",
    "    \n",
    "    return poisson_img.astype(cp.uint8)\n",
    "\n",
    "# Função para adicionar ruído Poisson + Gaussiano (com CuPy)\n",
    "def add_poisson_gaussian_noise(image, gaussian_sigma=25):\n",
    "    \"\"\"\n",
    "    Adiciona ruído de Poisson seguido de ruído Gaussiano a uma imagem.\n",
    "\n",
    "    Parâmetros:\n",
    "        image (cp.ndarray): imagem de entrada.\n",
    "        gaussian_sigma (float): desvio padrão do ruído gaussiano.\n",
    "\n",
    "    Retorna:\n",
    "        cp.ndarray: imagem com ruído Poisson + Gaussiano.\n",
    "    \"\"\"\n",
    "    # Aplica ruído Poisson\n",
    "    poisson_image = cp.random.poisson(image).astype(cp.float32)\n",
    "\n",
    "    # Aplica ruído Gaussiano\n",
    "    gaussian_noise = cp.random.normal(loc=0.0, scale=gaussian_sigma, size=image.shape)\n",
    "    noisy_image = poisson_image + gaussian_noise\n",
    "\n",
    "    # Clip para garantir que os valores fiquem entre 0 e 255\n",
    "    noisy_image = cp.clip(noisy_image, 0, 255).astype(cp.uint8)\n",
    "\n",
    "    return noisy_image\n",
    "\n",
    "# Função para downscale com CuPy\n",
    "def downscale_with_cp(image, scale_factor):\n",
    "    \"\"\"\n",
    "    Aplica downscale (média local) usando CuPy.\n",
    "    \n",
    "    Parâmetros:\n",
    "        image (cp.ndarray): imagem a ser redimensionada.\n",
    "        scale_factor (int): fator de escala para downscale.\n",
    "\n",
    "    Retorna:\n",
    "        cp.ndarray: imagem com downscale aplicada.\n",
    "    \"\"\"\n",
    "    m, n = image.shape\n",
    "    block_size = int(scale_factor)\n",
    "\n",
    "    # Verificar se a imagem é divisível pelo bloco\n",
    "    if m % block_size != 0 or n % block_size != 0:\n",
    "        raise ValueError(\"O tamanho da imagem não é divisível pelo tamanho do bloco.\")\n",
    "\n",
    "    image_reshaped = image.reshape(m // block_size, block_size, n // block_size, block_size)\n",
    "    downscaled = image_reshaped.mean(axis=(1, 3))  # Média local sobre os blocos\n",
    "    return cp.array(downscaled)\n",
    "\n",
    "# Função de transformação de Anscombe\n",
    "def anscombe_transform(img):\n",
    "    return 2.0 * cp.sqrt(img.astype(cp.float32) + 3.0 / 8.0)\n",
    "\n",
    "# Função inversa de Anscombe\n",
    "def inverse_anscombe(transf_img):\n",
    "    return cp.clip((transf_img / 2.0) ** 2 - 3.0 / 8.0, 0, 255)\n",
    "\n",
    "# Carregar a imagem\n",
    "img = skimage.io.imread('../images/0.gif')\n",
    "\n",
    "# Se a imagem for GIF, pegamos o primeiro quadro (se houver mais de um)\n",
    "img = img[0, :, :] if len(img.shape) > 2 else img\n",
    "\n",
    "# Se a imagem for colorida (RGB), converta para monocromática\n",
    "if len(img.shape) > 2:\n",
    "    img = skimage.color.rgb2gray(img)  # valores convertidos ficam entre 0 e 1\n",
    "    img = (255 * img).astype(cp.float32)  # Converter para [0, 255]\n",
    "\n",
    "# Redimensionar a imagem (downscale com NumPy)\n",
    "img_downscale = downscale_local_mean(img, (2, 2))\n",
    "\n",
    "# Redimensionar a imagem para CuPy\n",
    "img_downscale = cp.array(img_downscale).astype(cp.float32)\n",
    "\n",
    "m, n = img_downscale.shape\n",
    "\n",
    "# Adicionar ruído de Poisson\n",
    "noised_poisson = add_poisson_noise(img_downscale)\n",
    "\n",
    "# Adicionar ruído Poisson + Gaussiano\n",
    "noised_poissongaussian = add_poisson_gaussian_noise(img_downscale)\n",
    "\n",
    "# Garantir que as imagens de ruído fiquem entre 0 e 255\n",
    "noised_poisson[cp.where(noised_poisson > 255)] = 255\n",
    "noised_poisson[cp.where(noised_poisson < 0)] = 0\n",
    "\n",
    "noised_poissongaussian[cp.where(noised_poissongaussian > 255)] = 255\n",
    "noised_poissongaussian[cp.where(noised_poissongaussian < 0)] = 0\n",
    "\n",
    "# Selecionar o melhor h para NLM e GEONLM\n",
    "# Antes de usar estimate_sigma, converta para numpy\n",
    "img_downscale_np = img_downscale.get()  # Convertendo CuPy para NumPy\n",
    "sigma_est = estimate_sigma(img_downscale_np)  # Usando estimate_sigma no formato NumPy\n",
    "\n",
    "# Aqui você pode continuar com seu processo de seleção de h\n",
    "h_nlm, h_geo, q_nlm_candidates = select_best_h_using_adaptive_q(img_downscale, noised_poisson, f=4, t=7, alpha=0.5)\n",
    "\n",
    "# Exibir resultados\n",
    "print(f'h_nlm: {h_nlm}, h_geo: {h_geo}, q_nlm_candidates: {q_nlm_candidates}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# f = 4\n",
    "# t = 7\n",
    "# # Cria imagem de saída\n",
    "# filtered = np.zeros((m, n))\n",
    "\n",
    "# # Problema de valor de contorno: replicar bordas\n",
    "# img_noised_poisson = np.pad(noised_poisson, ((f, f), (f, f)), 'symmetric')\n",
    "# img_noised_poisson_gaussian = np.pad(noised_poissongaussian, ((f, f), (f, f)), 'symmetric')\n",
    "\n",
    "# noised_anscombe_poisson = anscombe_transform(img_noised_poisson)\n",
    "# noised_anscombe_poisson_gaussian = anscombe_transform(img_noised_poisson_gaussian)\n",
    "\n",
    "\n",
    "# sigma_est_poisson = estimate_sigma(noised_anscombe_poisson)\n",
    "# sigma_est_poisson_gaussian = estimate_sigma(noised_anscombe_poisson_gaussian)\n",
    "\n",
    "# q_nlm, q_geo = compute_adaptive_q(sigma_est)\n",
    "# h_nlm = q_nlm * sigma_est #* 10\n",
    "# h_geo = q_geo * sigma_est #* 10\n",
    "\n",
    "\n",
    "# start = time.time()\n",
    "# result_img_noised_poisson = NLM_fast_cuda_shared(img_noised_poisson, h, f, t)\n",
    "# result_img_noised_poisson_gaussian = NLM_fast_cuda_shared(img_noised_poisson_gaussian, h, f, t)\n",
    "\n",
    "cp.cuda.Stream.null.synchronize()  # espera terminar GPU\n",
    "#print(\"Tempo GPU:\", time.time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b22703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
